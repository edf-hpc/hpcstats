# Example of hpcstats.conf
# Most of the default values can be change and have to be adpated
# This file is not meant to be a ready to work one you might have to tune it
###############################################################################

[clusters]
clusters = cluster2,cluster1

[hpcstatsdb]
hostname = localhost
dbname = supervisiondb
port = 5432
user = <myuser>
password = <password>

# Importer constraints
###############################################################################
[constraints]
# This parameter specifies how hpcstats should behave when a user is a member
# of the group in LDAP directory but has not an account in this LDAP directory.
# If set to True (default value), hpcstats will fail (and stop running) when
# such error is encountered. If set to False, hpcstats will simply print a
# warning message, ignore this user and keep running.
strict_user_membership=True

# These parameters define whether hpcstats should either fail or just print an
# error if an imported job is linked to a projet (or respectively a business
# code) that has not been loaded by ProjectImporter (and BusinessCodeImporter)
# previously. If set to True (default value), hpcstats will fail (and stop
# running). Else hpstats will just print a warning and will set project and
# business references to NULL in HPCStatsDB.
strict_job_project_binding=True
strict_job_businesscode_binding=True

# This parameter controls if hpcstats should fail or just print an error when
# a job loaded by JobImporterSlurm has a wckey in a wrong format. When set to
# True (default) hpcstats will fail, when set to False hpcstats will simply
# print an error message.
strict_job_wckey_format=True

# Global parameters
###############################################################################

[globals]
business = csv
projects = csv

[business]
file = <absolute path to CSV file>

[projects]
file = <absolute path to CSV file>

# Cluster2
###############################################################################
[cluster2]
jobs = slurm
users = ldap
contexts = csv
fsusage = ssh

[cluster2/ldap]
url = ldaps://<ldapuri>/
dn = <dn>
basedn = <basedn>
phash = <password>
cert = /path/to/cert
group = <group>
rdn_people = ou=people
rdn_groups = ou=groups
group_dpt_search = *dp*
group_dpt_regexp = cn=(.+)-dp-(.+),ou.*

[cluster2/slurm]
host = <slurm_mysql_db_ip>
name = slurm_acct_db
user = slurm
password = <slurmpasswd>
# Defines whether login extracted from SlurmDBD must be uppercased before
# matching them with account loaded by UserImporter. Default is False.
uppercase_accounts = False
# When uppercase_accounts is True, it is possible to specify a list of
# account exceptions. These account names will not not be uppercased even
# if uppercase_accounts is True.
uppercase_exceptions = account1,account2
# When this parameter is set to a value N above 0, the new jobs will be
# loaded by JobImporterSlurm in windowed mode, N jobs at a time, until there
# are no jobs to load anymore. If set to 0 (default value), all jobs will be
# loaded at once and this can lead to a lot of memory consumption when there
# too many jobs. It is recommended to set this value to limit memory
# consumption during jobs import.
window_size = 1000

[cluster2/fsusage]
host = host IP
name = username
file = <absolute path to CSV file>
# The format of the timestamp to parse in remote log file.
# Default value is: %Y-%m-%dT%H:%M:%S.%fZ
timestamp_fmt = %Y-%m-%dT%H:%M:%S.%fZ

[cluster2/context]
file = <absolute path to CSV file>

# Cluster 1
###############################################################################
[cluster1]
jobs = torque
users = ldap

[cluster1/ldap]
url = ldaps://<ldapuri>/
dn = <dn>
basedn = <basedn>
phash = <password>
group = <group>
group_dpt_search = *dp*
group_dpt_regexp = cn=(.+)-dp-(.+),ou.*

[cluster1/torque]
logdir = <folder for torque log files>


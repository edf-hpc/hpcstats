# Example of hpcstats.conf
# Most of the default values can be change and have to be adpated
# This file is not meant to be a ready to work one you might have to tune it
###############################################################################

[clusters]
clusters = cluster1,cluster2

[hpcstatsdb]
hostname = localhost
dbname = hpcstatsdb
port = 5432
user = <myuser>
password = <password>

# Importer constraints
###############################################################################
[constraints]
# This parameter specifies how hpcstats should behave when a user is a member
# of the group in LDAP directory but has not an account in this LDAP directory.
# If set to True (default value), hpcstats will fail (and stop running) when
# such error is encountered. If set to False, hpcstats will simply print a
# warning message, ignore this user and keep running.
strict_user_membership=True

# These parameters define whether hpcstats should either fail or just print an
# error if an imported job is linked to a projet (or respectively a business
# code) that has not been loaded by ProjectImporter (and BusinessCodeImporter)
# previously. If set to True (default value), hpcstats will fail (and stop
# running). Else hpstats will just print a warning and will set project and
# business references to NULL in HPCStatsDB.
strict_job_project_binding=True
strict_job_businesscode_binding=True

# This parameter controls how hpcstats should behave when a loaded job was
# submitted by an account that has not been loaded by UserImporter. When, set
# to True, hpcstats will fail (and stop running) when such job is encountered.
# Else, hpcstats will just print a warning message and skip the job. Default
# value is True.
strict_job_account_binding=True

# This parameter controls if hpcstats should fail or just print an error when
# a job loaded by JobImporterSlurm has a wckey in a wrong format. When set to
# True (default) hpcstats will fail, when set to False hpcstats will simply
# print an error message.
strict_job_wckey_format=True

# Comma-separated list of errors to ignore during the importation process
#ignored_errors =

# Global parameters
###############################################################################

[globals]
business = csv
projects = slurm

[business]
file = <absolute path to CSV file>

[projects]
default_domain_key = dft
default_domain_name = Default domain

# Cluster 1
###############################################################################
[cluster1]
architecture = archfile
users = ldap
fsusage = ssh
events = slurm
jobs = slurm

[cluster1/archfile]
file = /path/to/archfile

[cluster1/ldap]
url = ldaps://<ldapuri>/
dn = <dn>
basedn = <basedn>
rdn_people = ou=people
rdn_groups = ou=groups
phash = <password>
cert = /path/to/cert
groups = <group1>,<group2>
group_dpt_search = *dp*
group_dpt_regexp = cn=(\w+)-dp-(\w+),ou=.*
# If the department cannot be defined based on user groups membership, it is
# defined based on the user primary group in LDAP directory and this default
# subdirection.
#default_subdir = unknown
# Optional alias file to associate group names to the organization directions
# for department names based on users primary group name.
#groups_alias_file = /etc/hpcstats/groups.alias


[cluster1/slurm]
host = <slurm_mysql_db_ip>
name = slurm_acct_db
user = slurm
password = <slurmpasswd>
# When this parameter is set to a value N above 0, the new jobs will be
# loaded by JobImporterSlurm in windowed mode, N jobs at a time, until there
# are no jobs to load anymore. If set to 0 (default value), all jobs will be
# loaded at once and this can lead to a lot of memory consumption when there
# too many jobs. It is recommended to set this value to limit memory
# consumption during jobs import.
window_size = 1000
# SlurmDBD clusters specific table names prefix. Default is cluster name.
# prefix = cluster
# Optionally restrict imported data from slurm (jobs, events, projects) to a
# specific list of slurm partitions of a cluster. The list is comma separated.
# partitions = compute,graphics

[cluster1/fsusage]
host = host IP
name = username
file = <absolute path to CSV file>
# The format of the timestamp to parse in remote log file.
# Default value is: %Y-%m-%dT%H:%M:%S.%fZ
timestamp_fmt = %Y-%m-%dT%H:%M:%S.%fZ

# Cluster2
###############################################################################
[cluster2]
architecture = archfile
users = ldap
fsusage = ssh
events = slurm
jobs = slurm

[cluster2/archfile]
file = /path/to/archfile

[cluster2/ldap]
url = ldaps://<ldapuri>/
dn = <dn>
basedn = <basedn>
phash = <password>
groups = <group1>
group_dpt_search = *dp*
group_dpt_regexp = cn=(.+)-dp-(.+),ou.*
# If the department cannot be defined based on user groups membership, it is
# defined based on the user primary group in LDAP directory and this default
# subdirection.
# default_subdir = unknown

[cluster2/slurm]
host = <slurm_mysql_db_ip>
name = slurm_acct_db
user = slurm
password = <slurmpasswd>

[cluster2/fsusage]
host = host IP
name = username
file = <absolute path to CSV file>
